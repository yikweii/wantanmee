{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SENTIMENT ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T11:35:54.274141Z",
     "iopub.status.busy": "2025-09-10T11:35:54.273836Z",
     "iopub.status.idle": "2025-09-10T11:36:30.815251Z",
     "shell.execute_reply": "2025-09-10T11:36:30.814434Z",
     "shell.execute_reply.started": "2025-09-10T11:35:54.274119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "comments_data2 = pd.read_csv(\"/kaggle/input/preprocessed/cleaned_sentiment2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T11:36:30.816870Z",
     "iopub.status.busy": "2025-09-10T11:36:30.816587Z",
     "iopub.status.idle": "2025-09-10T11:36:37.205615Z",
     "shell.execute_reply": "2025-09-10T11:36:37.204756Z",
     "shell.execute_reply.started": "2025-09-10T11:36:30.816838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(\n",
    "    comments_data2[[\"sentiment_comment\", \"suggested_model\"]].copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T11:37:08.360568Z",
     "iopub.status.busy": "2025-09-10T11:37:08.360289Z",
     "iopub.status.idle": "2025-09-10T11:37:08.365724Z",
     "shell.execute_reply": "2025-09-10T11:37:08.364875Z",
     "shell.execute_reply.started": "2025-09-10T11:37:08.360547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# Device\n",
    "# ---------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T11:37:08.928932Z",
     "iopub.status.busy": "2025-09-10T11:37:08.928668Z",
     "iopub.status.idle": "2025-09-10T11:38:05.307927Z",
     "shell.execute_reply": "2025-09-10T11:38:05.307291Z",
     "shell.execute_reply.started": "2025-09-10T11:37:08.928911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# ---------------------------\n",
    "# Prepare DataFrame\n",
    "# ---------------------------\n",
    "comments_data2 = comments_data2.reset_index(drop=True)\n",
    "#results = [\"\"] * len(comments_data2)\n",
    "\n",
    "# Try to resume from checkpoint\n",
    "checkpoint_file = \"/kaggle/working/sentiment_checkpoint.csv\"\n",
    "if os.path.exists(checkpoint_file):\n",
    "    print(\"ðŸ”„ Loading checkpoint...\")\n",
    "    comments_data2 = pd.read_csv(checkpoint_file)\n",
    "else:\n",
    "    comments_data2[\"sentiment_prediction\"] = \"\"  # init empty column\n",
    "    \n",
    "# ---------------------------\n",
    "# Define models\n",
    "# ---------------------------\n",
    "MODEL_NAMES = {\n",
    "    \"Twitter-RoBERTa-Latest\": \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    \"Multilingual-BERT\": \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "}\n",
    "\n",
    "tokenizers = {}\n",
    "models = {}\n",
    "\n",
    "for name, path in MODEL_NAMES.items():\n",
    "    tokenizers[name] = AutoTokenizer.from_pretrained(path)\n",
    "    models[name] = AutoModelForSequenceClassification.from_pretrained(path).to(device)\n",
    "    models[name].eval()  # turn off dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T11:38:53.513244Z",
     "iopub.status.busy": "2025-09-10T11:38:53.512562Z",
     "iopub.status.idle": "2025-09-10T11:50:38.782030Z",
     "shell.execute_reply": "2025-09-10T11:50:38.781032Z",
     "shell.execute_reply.started": "2025-09-10T11:38:53.513220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8  # adjust based on GPU memory\n",
    "SAVE_EVERY = 10000  # save every 10000 batches (tweak this)\n",
    "\n",
    "# ---------------------------\n",
    "# Batch inference per model\n",
    "# ---------------------------\n",
    "for model_name in MODEL_NAMES.keys():\n",
    "    idxs = comments_data2.index[\n",
    "        (comments_data2[\"suggested_model\"] == model_name) &\n",
    "        (comments_data2[\"sentiment_prediction\"].isna() | (comments_data2[\"sentiment_prediction\"] == \"\"))\n",
    "    ].tolist()  # unfinished rows\n",
    "\n",
    "    if not idxs:\n",
    "        print(f\"â„¹ï¸ No unfinished rows for {model_name}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {len(idxs)} comments for model {model_name}...\")\n",
    "    print(f\"ðŸ‘‰ Resuming {model_name} from idx {idxs[0]} to {idxs[-1]}\")\n",
    "\n",
    "    tokenizer = tokenizers[model_name]\n",
    "    model = models[model_name]\n",
    "\n",
    "    for batch_num, start in enumerate(tqdm(range(0, len(idxs), BATCH_SIZE))):\n",
    "        end = min(start + BATCH_SIZE, len(idxs))\n",
    "        batch_idxs = idxs[start:end]\n",
    "        batch_texts = [comments_data2.at[i, \"sentiment_comment\"] for i in batch_idxs]\n",
    "\n",
    "        # Tokenize\n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            probs = softmax(logits, dim=-1)\n",
    "            pred_labels = torch.argmax(probs, dim=-1).cpu().tolist()\n",
    "            pred_scores = probs.max(dim=-1).values.cpu().tolist()\n",
    "\n",
    "        # Map label indices to string labels\n",
    "        if model_name == \"Twitter-RoBERTa-Latest\":\n",
    "            label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "        else:  # Multilingual-BERT 1â€“5 stars\n",
    "            label_map = {0: \"1 star\", 1: \"2 stars\", 2: \"3 stars\", 3: \"4 stars\", 4: \"5 stars\"}\n",
    "\n",
    "        # Save results back into DataFrame\n",
    "        for i, label_idx, score in zip(batch_idxs, pred_labels, pred_scores):\n",
    "            comments_data2.at[i, \"sentiment_prediction\"] = f\"{label_map[label_idx]} ({round(score, 3)})\"\n",
    "\n",
    "        # Save checkpoint every SAVE_EVERY batches\n",
    "        if (batch_num + 1) % SAVE_EVERY == 0:\n",
    "            comments_data2.to_csv(checkpoint_file, index=False)\n",
    "            print(f\"ðŸ’¾ Checkpoint saved at batch {batch_num+1}\")\n",
    "\n",
    "# Final save\n",
    "comments_data2.to_csv(checkpoint_file, index=False)\n",
    "print(\"âœ… All done! Results saved to\", checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-10T10:07:37.996Z",
     "iopub.execute_input": "2025-09-10T05:48:22.369392Z",
     "iopub.status.busy": "2025-09-10T05:48:22.369110Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8  # adjust based on GPU memory\n",
    "SAVE_EVERY = 10000  # save every 10000 batches (tweak this)\n",
    "\n",
    "# ---------------------------\n",
    "# Batch inference per model\n",
    "# ---------------------------\n",
    "for model_name in MODEL_NAMES.keys():\n",
    "    idxs = comments_data2.index[\n",
    "        (comments_data2[\"suggested_model\"] == model_name) &\n",
    "        (comments_data2[\"sentiment_prediction\"].isna() | (comments_data2[\"sentiment_prediction\"] == \"\"))\n",
    "    ].tolist()  # unfinished rows\n",
    "\n",
    "    if not idxs:\n",
    "        print(f\"â„¹ï¸ No unfinished rows for {model_name}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {len(idxs)} comments for model {model_name}...\")\n",
    "    print(f\"ðŸ‘‰ Resuming {model_name} from idx {idxs[0]} to {idxs[-1]}\")\n",
    "\n",
    "    tokenizer = tokenizers[model_name]\n",
    "    model = models[model_name]\n",
    "\n",
    "    for batch_num, start in enumerate(tqdm(range(0, len(idxs), BATCH_SIZE))):\n",
    "        end = min(start + BATCH_SIZE, len(idxs))\n",
    "        batch_idxs = idxs[start:end]\n",
    "        batch_texts = [comments_data2.at[i, \"sentiment_comment\"] for i in batch_idxs]\n",
    "\n",
    "        # Tokenize\n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            probs = softmax(logits, dim=-1)\n",
    "            pred_labels = torch.argmax(probs, dim=-1).cpu().tolist()\n",
    "            pred_scores = probs.max(dim=-1).values.cpu().tolist()\n",
    "\n",
    "        # Map label indices to string labels\n",
    "        if model_name == \"Twitter-RoBERTa-Latest\":\n",
    "            label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "        else:  # Multilingual-BERT 1â€“5 stars\n",
    "            label_map = {0: \"1 star\", 1: \"2 stars\", 2: \"3 stars\", 3: \"4 stars\", 4: \"5 stars\"}\n",
    "\n",
    "        # Save results back into DataFrame\n",
    "        for i, label_idx, score in zip(batch_idxs, pred_labels, pred_scores):\n",
    "            comments_data2.at[i, \"sentiment_prediction\"] = f\"{label_map[label_idx]} ({round(score, 3)})\"\n",
    "\n",
    "        # Save checkpoint every SAVE_EVERY batches\n",
    "        if (batch_num + 1) % SAVE_EVERY == 0:\n",
    "            comments_data2.to_csv(checkpoint_file, index=False)\n",
    "            print(f\"ðŸ’¾ Checkpoint saved at batch {batch_num+1}\")\n",
    "\n",
    "# Final save\n",
    "comments_data2.to_csv(checkpoint_file, index=False)\n",
    "print(\"âœ… All done! Results saved to\", checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T11:31:31.072737Z",
     "iopub.status.busy": "2025-09-10T11:31:31.071994Z",
     "iopub.status.idle": "2025-09-10T11:32:00.256152Z",
     "shell.execute_reply": "2025-09-10T11:32:00.255454Z",
     "shell.execute_reply.started": "2025-09-10T11:31:31.072714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/kaggle/working/sentiment_checkpoint.csv')\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T11:34:46.281468Z",
     "iopub.status.busy": "2025-09-10T11:34:46.281183Z",
     "iopub.status.idle": "2025-09-10T11:35:10.715691Z",
     "shell.execute_reply": "2025-09-10T11:35:10.714937Z",
     "shell.execute_reply.started": "2025-09-10T11:34:46.281447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/kaggle/working/sentiment_checkpoint.csv')\n",
    "data.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T11:50:50.513476Z",
     "iopub.status.busy": "2025-09-10T11:50:50.512747Z",
     "iopub.status.idle": "2025-09-10T11:50:50.557899Z",
     "shell.execute_reply": "2025-09-10T11:50:50.557253Z",
     "shell.execute_reply.started": "2025-09-10T11:50:50.513451Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 7ï¸âƒ£ Save back to DataFrame\n",
    "# ---------------------------\n",
    "comments_data2[\"sentiment_prediction\"] = data[\"sentiment_prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T11:51:01.866417Z",
     "iopub.status.busy": "2025-09-10T11:51:01.866169Z",
     "iopub.status.idle": "2025-09-10T11:51:48.669775Z",
     "shell.execute_reply": "2025-09-10T11:51:48.668965Z",
     "shell.execute_reply.started": "2025-09-10T11:51:01.866400Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "comments_data2.to_csv(\"/kaggle/working/sentiment_prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T11:51:48.671258Z",
     "iopub.status.busy": "2025-09-10T11:51:48.670878Z",
     "iopub.status.idle": "2025-09-10T11:51:48.682568Z",
     "shell.execute_reply": "2025-09-10T11:51:48.681784Z",
     "shell.execute_reply.started": "2025-09-10T11:51:48.671239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "comments_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T11:52:04.488088Z",
     "iopub.status.busy": "2025-09-10T11:52:04.487503Z",
     "iopub.status.idle": "2025-09-10T11:52:04.499326Z",
     "shell.execute_reply": "2025-09-10T11:52:04.498718Z",
     "shell.execute_reply.started": "2025-09-10T11:52:04.488057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "comments_data2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RELEVANCE ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T15:30:55.132717Z",
     "iopub.status.busy": "2025-09-10T15:30:55.132423Z",
     "iopub.status.idle": "2025-09-10T15:31:26.934571Z",
     "shell.execute_reply": "2025-09-10T15:31:26.933946Z",
     "shell.execute_reply.started": "2025-09-10T15:30:55.132692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "joined_data = pd.read_csv(\"/kaggle/input/relevant-data-test/comments_with_video_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T15:31:26.936477Z",
     "iopub.status.busy": "2025-09-10T15:31:26.935911Z",
     "iopub.status.idle": "2025-09-10T15:31:26.962500Z",
     "shell.execute_reply": "2025-09-10T15:31:26.961623Z",
     "shell.execute_reply.started": "2025-09-10T15:31:26.936450Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "joined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T15:44:59.769133Z",
     "iopub.status.busy": "2025-09-10T15:44:59.768734Z",
     "iopub.status.idle": "2025-09-10T15:44:59.773129Z",
     "shell.execute_reply": "2025-09-10T15:44:59.772236Z",
     "shell.execute_reply.started": "2025-09-10T15:44:59.769111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "CHECKPOINT_FILE = \"/kaggle/working/joined_data_with_similarity.csv\"\n",
    "SAVE_EVERY = 10000  \n",
    "BATCH_SIZE = 32     # GPU mini-batch size\n",
    "MODEL_NAME = \"paraphrase-multilingual-MiniLM-L12-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T15:45:03.127163Z",
     "iopub.status.busy": "2025-09-10T15:45:03.126496Z",
     "iopub.status.idle": "2025-09-10T15:45:06.169596Z",
     "shell.execute_reply": "2025-09-10T15:45:06.168667Z",
     "shell.execute_reply.started": "2025-09-10T15:45:03.127137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# LOAD MODEL (GPU if available)\n",
    "# -------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = SentenceTransformer(MODEL_NAME, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T15:45:06.171018Z",
     "iopub.status.busy": "2025-09-10T15:45:06.170811Z",
     "iopub.status.idle": "2025-09-10T15:45:07.420342Z",
     "shell.execute_reply": "2025-09-10T15:45:07.419531Z",
     "shell.execute_reply.started": "2025-09-10T15:45:06.171001Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# If checkpoint exists, resume\n",
    "if os.path.exists(CHECKPOINT_FILE):\n",
    "    joined_data = pd.read_csv(CHECKPOINT_FILE)\n",
    "    print(f\"Resumed from checkpoint: {CHECKPOINT_FILE}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ No checkpoint found. Creating new file: {CHECKPOINT_FILE}\")\n",
    "    # if you are creating new, you must load the raw joined_data first\n",
    "    # e.g., joined_data = pd.read_csv(\"joined_data.csv\")\n",
    "    joined_data[\"similarity_score\"] = None\n",
    "    joined_data[\"relevance\"] = None\n",
    "\n",
    "# Add missing columns\n",
    "if \"similarity_score\" not in joined_data.columns:\n",
    "    joined_data[\"similarity_score\"] = None\n",
    "if \"relevance\" not in joined_data.columns:\n",
    "    joined_data[\"relevance\"] = None\n",
    "\n",
    "# Ensure text columns are strings (replace NaN/float with empty string)\n",
    "joined_data[\"video_text\"] = joined_data[\"video_text\"].astype(str).fillna(\"\")\n",
    "joined_data[\"sentiment_comment\"] = joined_data[\"sentiment_comment\"].astype(str).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T15:45:19.793183Z",
     "iopub.status.busy": "2025-09-10T15:45:19.792906Z",
     "iopub.status.idle": "2025-09-10T18:16:13.343086Z",
     "shell.execute_reply": "2025-09-10T18:16:13.342182Z",
     "shell.execute_reply.started": "2025-09-10T15:45:19.793162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# FIND unfinished rows\n",
    "# -------------------------\n",
    "idxs = joined_data.index[\n",
    "    (joined_data[\"similarity_score\"].isna()) |\n",
    "    (joined_data[\"similarity_score\"] == \"\")\n",
    "].tolist()\n",
    "\n",
    "if not idxs:\n",
    "    print(\"â„¹ï¸ No unfinished rows â€” everything already processed.\")\n",
    "else:\n",
    "    print(f\"Processing {len(idxs)} rows for model {MODEL_NAME}...\")\n",
    "    print(f\"ðŸ‘‰ Resuming from idx {idxs[0]} to {idxs[-1]}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # PROCESS IN BATCHES\n",
    "    # -------------------------\n",
    "    for batch_num, start in enumerate(\n",
    "        tqdm(range(0, len(idxs), BATCH_SIZE), desc=\"Batches\")\n",
    "    ):\n",
    "        end = min(start + BATCH_SIZE, len(idxs))\n",
    "        batch_idxs = idxs[start:end]\n",
    "        batch = joined_data.loc[batch_idxs]\n",
    "\n",
    "        # Encode\n",
    "        video_vecs = model.encode(\n",
    "            batch[\"video_text\"].tolist(),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            convert_to_tensor=True,\n",
    "            device=device,\n",
    "            show_progress_bar=False,\n",
    "        )\n",
    "        comment_vecs = model.encode(\n",
    "            batch[\"sentiment_comment\"].tolist(),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            convert_to_tensor=True,\n",
    "            device=device,\n",
    "            show_progress_bar=False,\n",
    "        )\n",
    "\n",
    "        # Similarity\n",
    "        sims = util.cos_sim(video_vecs, comment_vecs).diagonal().cpu().tolist()\n",
    "\n",
    "        # Save results\n",
    "        joined_data.loc[batch_idxs, \"similarity_score\"] = sims\n",
    "        joined_data.loc[batch_idxs, \"relevance\"] = [\n",
    "            \"Relevant\" if s > 0.4 else \"Not relevant\" for s in sims\n",
    "        ]\n",
    "\n",
    "        # Save checkpoint every SAVE_EVERY batches\n",
    "        if (batch_num + 1) % SAVE_EVERY == 0:\n",
    "            joined_data.to_csv(CHECKPOINT_FILE, index=False)\n",
    "            rows_done = (batch_num + 1) * BATCH_SIZE\n",
    "            rows_left = len(idxs) - rows_done\n",
    "            print(f\"ðŸ’¾ Checkpoint saved at batch {batch_num+1} \"\n",
    "                  f\"({rows_done}/{len(idxs)} rows, {rows_left} left)\")\n",
    "\n",
    "    # -------------------------\n",
    "    # FINAL SAVE\n",
    "    # -------------------------\n",
    "    joined_data.to_csv(CHECKPOINT_FILE, index=False)\n",
    "    print(f\"âœ… All done! Results saved to {CHECKPOINT_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8174701,
     "sourceId": 12919256,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8233355,
     "sourceId": 13005339,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8243445,
     "sourceId": 13019971,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
